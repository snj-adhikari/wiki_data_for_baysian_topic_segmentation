{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mixFiles.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "owMPoaA1oCrU",
        "VBzox9GlIP6r",
        "ytU5PbQJh5G6",
        "jifKK2psh5G2",
        "xTtnwusVhItb",
        "UiUTTxlL484C",
        "t8a3bXtihAF1",
        "BGJwA9-VIfAZ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP-2lwx9-0XH",
        "colab_type": "text"
      },
      "source": [
        "## Baysian Topic Segmentation . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o6Nf8VX-_gX",
        "colab_type": "text"
      },
      "source": [
        "This code is based on analysis on the basis Baysian Unsupervised Topic segmentation 2008 by Jacob Eisentien and Regina Barzilay, Computer Science and Artificial Intelligence Laboratory , Massachusetts Institute of Technology. \n",
        "The code and paper is refered from the following [ link](http://groups.csail.mit.edu/rbg/code/bayesseg/bayesseg.tar.gz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owMPoaA1oCrU",
        "colab_type": "text"
      },
      "source": [
        "# Downloading and evaluating the base code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1KGF4zWnfqb",
        "colab_type": "code",
        "outputId": "20d4280d-224b-4648-f874-4fcf111ace9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://groups.csail.mit.edu/rbg/code/bayesseg/bayesseg.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-03 05:37:21--  http://groups.csail.mit.edu/rbg/code/bayesseg/bayesseg.tar.gz\n",
            "Resolving groups.csail.mit.edu (groups.csail.mit.edu)... 128.30.2.44\n",
            "Connecting to groups.csail.mit.edu (groups.csail.mit.edu)|128.30.2.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4687672 (4.5M) [application/x-gzip]\n",
            "Saving to: ‘bayesseg.tar.gz’\n",
            "\n",
            "\rbayesseg.tar.gz       0%[                    ]       0  --.-KB/s               \rbayesseg.tar.gz     100%[===================>]   4.47M  23.1MB/s    in 0.2s    \n",
            "\n",
            "2019-09-03 05:37:21 (23.1 MB/s) - ‘bayesseg.tar.gz’ saved [4687672/4687672]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZVuThc-oLRy",
        "colab_type": "code",
        "outputId": "a86d75d0-654b-4d7a-e4b3-7b371bb47467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!tar zxvf bayesseg.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bayesseg/baselines/\n",
            "bayesseg/baselines/textseg-1.211/\n",
            "bayesseg/baselines/textseg-1.211/data/\n",
            "bayesseg/baselines/textseg-1.211/data/comp/\n",
            "bayesseg/baselines/textseg-1.211/data/org/\n",
            "bayesseg/baselines/textseg-1.211/data/t/\n",
            "bayesseg/baselines/textseg-1.211/doc/\n",
            "bayesseg/baselines/textseg-1.211/doc/eng/\n",
            "bayesseg/classes/\n",
            "bayesseg/classes/edu/\n",
            "bayesseg/classes/edu/mit/\n",
            "bayesseg/classes/edu/mit/multimodal/\n",
            "bayesseg/classes/edu/mit/multimodal/motifs/\n",
            "bayesseg/classes/edu/mit/nlp/\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/dp/\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/mcmc/\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/wrappers/\n",
            "bayesseg/classes/edu/mit/util/\n",
            "bayesseg/classes/edu/mit/util/ling/\n",
            "bayesseg/classes/edu/mit/util/stats/\n",
            "bayesseg/classes/edu/mit/util/weka/\n",
            "bayesseg/classes/riso/\n",
            "bayesseg/classes/riso/numerical/\n",
            "bayesseg/config/\n",
            "bayesseg/data/\n",
            "bayesseg/data/books/\n",
            "bayesseg/data/books/clinical/\n",
            "bayesseg/data/icsi/\n",
            "bayesseg/data/icsi/scripts/\n",
            "bayesseg/data/icsi/segs/\n",
            "bayesseg/doc/\n",
            "bayesseg/doc/api/\n",
            "bayesseg/doc/api/edu/\n",
            "bayesseg/doc/api/edu/mit/\n",
            "bayesseg/doc/api/edu/mit/nlp/\n",
            "bayesseg/doc/api/edu/mit/nlp/class-use/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/class-use/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/class-use/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/class-use/\n",
            "bayesseg/doc/api/edu/mit/util/\n",
            "bayesseg/doc/api/edu/mit/util/class-use/\n",
            "bayesseg/doc/api/edu/mit/util/ling/\n",
            "bayesseg/doc/api/edu/mit/util/ling/class-use/\n",
            "bayesseg/doc/api/edu/mit/util/stats/\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/\n",
            "bayesseg/doc/api/edu/mit/util/weka/\n",
            "bayesseg/doc/api/edu/mit/util/weka/class-use/\n",
            "bayesseg/doc/api/resources/\n",
            "bayesseg/lib/\n",
            "bayesseg/source/\n",
            "bayesseg/source/edu/\n",
            "bayesseg/source/edu/mit/\n",
            "bayesseg/source/edu/mit/nlp/\n",
            "bayesseg/source/edu/mit/nlp/segmenter/\n",
            "bayesseg/source/edu/mit/nlp/segmenter/dp/\n",
            "bayesseg/source/edu/mit/nlp/segmenter/mcmc/\n",
            "bayesseg/source/edu/mit/nlp/segmenter/wrappers/\n",
            "bayesseg/source/edu/mit/nlp/util/\n",
            "bayesseg/source/edu/mit/util/\n",
            "bayesseg/source/edu/mit/util/ling/\n",
            "bayesseg/source/edu/mit/util/stats/\n",
            "bayesseg/source/edu/mit/util/weka/\n",
            "bayesseg/source/riso/\n",
            "bayesseg/source/riso/numerical/\n",
            "bayesseg/README\n",
            "bayesseg/baselines/textseg-1.211.tar\n",
            "bayesseg/baselines/textseg-1.211/COPYING\n",
            "bayesseg/baselines/textseg-1.211/ChangeLog\n",
            "bayesseg/baselines/textseg-1.211/ESeg\n",
            "bayesseg/baselines/textseg-1.211/Experiments\n",
            "bayesseg/baselines/textseg-1.211/Install-guide\n",
            "bayesseg/baselines/textseg-1.211/JSeg\n",
            "bayesseg/baselines/textseg-1.211/Makefile\n",
            "bayesseg/baselines/textseg-1.211/PStemmer.class\n",
            "bayesseg/baselines/textseg-1.211/PStemmer.java\n",
            "bayesseg/baselines/textseg-1.211/README\n",
            "bayesseg/baselines/textseg-1.211/README.ja\n",
            "bayesseg/baselines/textseg-1.211/Seg\n",
            "bayesseg/baselines/textseg-1.211/cstemmer\n",
            "bayesseg/baselines/textseg-1.211/cstemmer.pl\n",
            "bayesseg/baselines/textseg-1.211/data/comp/TestLog100.txt.org\n",
            "bayesseg/baselines/textseg-1.211/data/comp/TestLog110.txt.org\n",
            "bayesseg/baselines/textseg-1.211/data/org/000115020000921001.txt\n",
            "bayesseg/baselines/textseg-1.211/data/org/gijiroku.cstemmer.words\n",
            "bayesseg/baselines/textseg-1.211/data/org/gijiroku.jseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/gijiroku.txt\n",
            "bayesseg/baselines/textseg-1.211/data/org/gijiroku.vseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.Seg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.bseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.eseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.mwn.words\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.mwnp.words\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.nseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.pstemmer.words\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.rseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.rseg2\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.seg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.seg.comb\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.seg1\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.seg1.comb\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.txt\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.vseg\n",
            "bayesseg/baselines/textseg-1.211/data/org/stargazers.vseg.comb\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.Seg\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.nseg\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.pstemmer.words\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.rseg\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.rseg2\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.seg\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.seg.comb\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.vseg\n",
            "bayesseg/baselines/textseg-1.211/data/t/stargazers.vseg.comb\n",
            "bayesseg/baselines/textseg-1.211/diff.pl\n",
            "bayesseg/baselines/textseg-1.211/doc/eng/acl2001.pdf\n",
            "bayesseg/baselines/textseg-1.211/nseg\n",
            "bayesseg/baselines/textseg-1.211/nseg.c\n",
            "bayesseg/baselines/textseg-1.211/prep-seg\n",
            "bayesseg/baselines/textseg-1.211/pstemmer\n",
            "bayesseg/baselines/textseg-1.211/rseg\n",
            "bayesseg/baselines/textseg-1.211/rseg.c\n",
            "bayesseg/baselines/textseg-1.211/rseg2\n",
            "bayesseg/baselines/textseg-1.211/seg\n",
            "bayesseg/baselines/textseg-1.211/seg-comb\n",
            "bayesseg/baselines/textseg-1.211/seg.c\n",
            "bayesseg/baselines/textseg-1.211/stat.pl\n",
            "bayesseg/baselines/textseg-1.211/vseg\n",
            "bayesseg/baselines/textseg-1.211/vseg.c\n",
            "bayesseg/build.xml\n",
            "bayesseg/classes/edu/mit/multimodal/motifs/MultiEval$1.class\n",
            "bayesseg/classes/edu/mit/multimodal/motifs/MultiEval.class\n",
            "bayesseg/classes/edu/mit/nlp/MyTextWrapper.class\n",
            "bayesseg/classes/edu/mit/nlp/ParaData.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/Document.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/InitializableSegmenter.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/PerfectSegmenter.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/SegEval.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/SegResult.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/SegTester$1.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/SegTester.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/SegTesterParams.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/Segment.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/Segmenter.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/dp/BayesWrapper.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/dp/DPDocument.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/dp/DPSeg$PriorOptimizer.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/dp/DPSeg.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/dp/I2JInterface.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/mcmc/CuCoSeg$PriorOptimizer.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/mcmc/CuCoSeg$Unigram.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/mcmc/CuCoSeg.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/wrappers/LCSegWrapper.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/wrappers/MCSWrapper.class\n",
            "bayesseg/classes/edu/mit/nlp/segmenter/wrappers/UIWrapper.class\n",
            "bayesseg/classes/edu/mit/util/JacobUtil.class\n",
            "bayesseg/classes/edu/mit/util/ling/CountsManager.class\n",
            "bayesseg/classes/edu/mit/util/ling/Stemmer.class\n",
            "bayesseg/classes/edu/mit/util/stats/Annealer.class\n",
            "bayesseg/classes/edu/mit/util/stats/FastDCM.class\n",
            "bayesseg/classes/edu/mit/util/stats/FastDigamma.class\n",
            "bayesseg/classes/edu/mit/util/stats/FastDoubleGamma.class\n",
            "bayesseg/classes/edu/mit/util/stats/FastGamma.class\n",
            "bayesseg/classes/edu/mit/util/stats/FastIntGamma.class\n",
            "bayesseg/classes/edu/mit/util/stats/ResultTracker.class\n",
            "bayesseg/classes/edu/mit/util/stats/Results.class\n",
            "bayesseg/classes/edu/mit/util/stats/Stats.class\n",
            "bayesseg/classes/edu/mit/util/weka/LBFGSWrapper.class\n",
            "bayesseg/classes/riso/numerical/LBFGS$ExceptionWithIflag.class\n",
            "bayesseg/classes/riso/numerical/LBFGS.class\n",
            "bayesseg/classes/riso/numerical/Mcsrch.class\n",
            "bayesseg/config/CUEPHRASES.hl\n",
            "bayesseg/config/STOPWORD.list\n",
            "bayesseg/config/cue.config\n",
            "bayesseg/config/dp.config\n",
            "bayesseg/config/lcseg.config\n",
            "bayesseg/config/mcsopt.ai.config\n",
            "bayesseg/config/perfect.config\n",
            "bayesseg/config/ui.config\n",
            "bayesseg/data/books/clinical/000.ref\n",
            "bayesseg/data/books/clinical/001.ref\n",
            "bayesseg/data/books/clinical/002.ref\n",
            "bayesseg/data/books/clinical/003.ref\n",
            "bayesseg/data/books/clinical/004.ref\n",
            "bayesseg/data/books/clinical/005.ref\n",
            "bayesseg/data/books/clinical/006.ref\n",
            "bayesseg/data/books/clinical/007.ref\n",
            "bayesseg/data/books/clinical/008.ref\n",
            "bayesseg/data/books/clinical/009.ref\n",
            "bayesseg/data/books/clinical/010.ref\n",
            "bayesseg/data/books/clinical/011.ref\n",
            "bayesseg/data/books/clinical/012.ref\n",
            "bayesseg/data/books/clinical/013.ref\n",
            "bayesseg/data/books/clinical/014.ref\n",
            "bayesseg/data/books/clinical/015.ref\n",
            "bayesseg/data/books/clinical/016.ref\n",
            "bayesseg/data/books/clinical/017.ref\n",
            "bayesseg/data/books/clinical/018.ref\n",
            "bayesseg/data/books/clinical/019.ref\n",
            "bayesseg/data/books/clinical/020.ref\n",
            "bayesseg/data/books/clinical/021.ref\n",
            "bayesseg/data/books/clinical/022.ref\n",
            "bayesseg/data/books/clinical/023.ref\n",
            "bayesseg/data/books/clinical/024.ref\n",
            "bayesseg/data/books/clinical/025.ref\n",
            "bayesseg/data/books/clinical/026.ref\n",
            "bayesseg/data/books/clinical/027.ref\n",
            "bayesseg/data/books/clinical/028.ref\n",
            "bayesseg/data/books/clinical/029.ref\n",
            "bayesseg/data/books/clinical/030.ref\n",
            "bayesseg/data/books/clinical/031.ref\n",
            "bayesseg/data/books/clinical/032.ref\n",
            "bayesseg/data/books/clinical/033.ref\n",
            "bayesseg/data/books/clinical/034.ref\n",
            "bayesseg/data/books/clinical/035.ref\n",
            "bayesseg/data/books/clinical/036.ref\n",
            "bayesseg/data/books/clinical/037.ref\n",
            "bayesseg/data/books/clinical/038.ref\n",
            "bayesseg/data/books/clinical/039.ref\n",
            "bayesseg/data/books/clinical/040.ref\n",
            "bayesseg/data/books/clinical/041.ref\n",
            "bayesseg/data/books/clinical/042.ref\n",
            "bayesseg/data/books/clinical/043.ref\n",
            "bayesseg/data/books/clinical/044.ref\n",
            "bayesseg/data/books/clinical/045.ref\n",
            "bayesseg/data/books/clinical/046.ref\n",
            "bayesseg/data/books/clinical/047.ref\n",
            "bayesseg/data/books/clinical/048.ref\n",
            "bayesseg/data/books/clinical/049.ref\n",
            "bayesseg/data/books/clinical/050.ref\n",
            "bayesseg/data/books/clinical/051.ref\n",
            "bayesseg/data/books/clinical/052.ref\n",
            "bayesseg/data/books/clinical/053.ref\n",
            "bayesseg/data/books/clinical/054.ref\n",
            "bayesseg/data/books/clinical/055.ref\n",
            "bayesseg/data/books/clinical/056.ref\n",
            "bayesseg/data/books/clinical/057.ref\n",
            "bayesseg/data/books/clinical/058.ref\n",
            "bayesseg/data/books/clinical/059.ref\n",
            "bayesseg/data/books/clinical/060.ref\n",
            "bayesseg/data/books/clinical/061.ref\n",
            "bayesseg/data/books/clinical/062.ref\n",
            "bayesseg/data/books/clinical/063.ref\n",
            "bayesseg/data/books/clinical/064.ref\n",
            "bayesseg/data/books/clinical/065.ref\n",
            "bayesseg/data/books/clinical/066.ref\n",
            "bayesseg/data/books/clinical/067.ref\n",
            "bayesseg/data/books/clinical/068.ref\n",
            "bayesseg/data/books/clinical/069.ref\n",
            "bayesseg/data/books/clinical/070.ref\n",
            "bayesseg/data/books/clinical/071.ref\n",
            "bayesseg/data/books/clinical/072.ref\n",
            "bayesseg/data/books/clinical/073.ref\n",
            "bayesseg/data/books/clinical/074.ref\n",
            "bayesseg/data/books/clinical/075.ref\n",
            "bayesseg/data/books/clinical/076.ref\n",
            "bayesseg/data/books/clinical/077.ref\n",
            "bayesseg/data/books/clinical/078.ref\n",
            "bayesseg/data/books/clinical/079.ref\n",
            "bayesseg/data/books/clinical/080.ref\n",
            "bayesseg/data/books/clinical/081.ref\n",
            "bayesseg/data/books/clinical/082.ref\n",
            "bayesseg/data/books/clinical/083.ref\n",
            "bayesseg/data/books/clinical/084.ref\n",
            "bayesseg/data/books/clinical/085.ref\n",
            "bayesseg/data/books/clinical/086.ref\n",
            "bayesseg/data/books/clinical/087.ref\n",
            "bayesseg/data/books/clinical/088.ref\n",
            "bayesseg/data/books/clinical/089.ref\n",
            "bayesseg/data/books/clinical/090.ref\n",
            "bayesseg/data/books/clinical/091.ref\n",
            "bayesseg/data/books/clinical/092.ref\n",
            "bayesseg/data/books/clinical/093.ref\n",
            "bayesseg/data/books/clinical/094.ref\n",
            "bayesseg/data/books/clinical/095.ref\n",
            "bayesseg/data/books/clinical/096.ref\n",
            "bayesseg/data/books/clinical/097.ref\n",
            "bayesseg/data/books/clinical/098.ref\n",
            "bayesseg/data/books/clinical/099.ref\n",
            "bayesseg/data/books/clinical/100.ref\n",
            "bayesseg/data/books/clinical/101.ref\n",
            "bayesseg/data/books/clinical/102.ref\n",
            "bayesseg/data/books/clinical/103.ref\n",
            "bayesseg/data/books/clinical/104.ref\n",
            "bayesseg/data/books/clinical/105.ref\n",
            "bayesseg/data/books/clinical/106.ref\n",
            "bayesseg/data/books/clinical/107.ref\n",
            "bayesseg/data/books/clinical/108.ref\n",
            "bayesseg/data/books/clinical/109.ref\n",
            "bayesseg/data/books/clinical/110.ref\n",
            "bayesseg/data/books/clinical/111.ref\n",
            "bayesseg/data/books/clinical/112.ref\n",
            "bayesseg/data/books/clinical/113.ref\n",
            "bayesseg/data/books/clinical/114.ref\n",
            "bayesseg/data/books/clinical/115.ref\n",
            "bayesseg/data/books/clinical/116.ref\n",
            "bayesseg/data/books/clinical/117.ref\n",
            "bayesseg/data/books/clinical/118.ref\n",
            "bayesseg/data/books/clinical/119.ref\n",
            "bayesseg/data/books/clinical/120.ref\n",
            "bayesseg/data/books/clinical/121.ref\n",
            "bayesseg/data/books/clinical/122.ref\n",
            "bayesseg/data/books/clinical/123.ref\n",
            "bayesseg/data/books/clinical/124.ref\n",
            "bayesseg/data/books/clinical/125.ref\n",
            "bayesseg/data/books/clinical/126.ref\n",
            "bayesseg/data/books/clinical/127.ref\n",
            "bayesseg/data/books/clinical/128.ref\n",
            "bayesseg/data/books/clinical/129.ref\n",
            "bayesseg/data/books/clinical/130.ref\n",
            "bayesseg/data/books/clinical/131.ref\n",
            "bayesseg/data/books/clinical/132.ref\n",
            "bayesseg/data/books/clinical/133.ref\n",
            "bayesseg/data/books/clinical/134.ref\n",
            "bayesseg/data/books/clinical/135.ref\n",
            "bayesseg/data/books/clinical/136.ref\n",
            "bayesseg/data/books/clinical/137.ref\n",
            "bayesseg/data/books/clinical/138.ref\n",
            "bayesseg/data/books/clinical/139.ref\n",
            "bayesseg/data/books/clinical/140.ref\n",
            "bayesseg/data/books/clinical/141.ref\n",
            "bayesseg/data/books/clinical/142.ref\n",
            "bayesseg/data/books/clinical/143.ref\n",
            "bayesseg/data/books/clinical/144.ref\n",
            "bayesseg/data/books/clinical/145.ref\n",
            "bayesseg/data/books/clinical/146.ref\n",
            "bayesseg/data/books/clinical/147.ref\n",
            "bayesseg/data/books/clinical/148.ref\n",
            "bayesseg/data/books/clinical/149.ref\n",
            "bayesseg/data/books/clinical/150.ref\n",
            "bayesseg/data/books/clinical/151.ref\n",
            "bayesseg/data/books/clinical/152.ref\n",
            "bayesseg/data/books/clinical/153.ref\n",
            "bayesseg/data/books/clinical/154.ref\n",
            "bayesseg/data/books/clinical/155.ref\n",
            "bayesseg/data/books/clinical/156.ref\n",
            "bayesseg/data/books/clinical/157.ref\n",
            "bayesseg/data/books/clinical/158.ref\n",
            "bayesseg/data/books/clinical/159.ref\n",
            "bayesseg/data/books/clinical/160.ref\n",
            "bayesseg/data/books/clinical/161.ref\n",
            "bayesseg/data/books/clinical/162.ref\n",
            "bayesseg/data/books/clinical/163.ref\n",
            "bayesseg/data/books/clinical/164.ref\n",
            "bayesseg/data/books/clinical/165.ref\n",
            "bayesseg/data/books/clinical/166.ref\n",
            "bayesseg/data/books/clinical/167.ref\n",
            "bayesseg/data/books/clinical/168.ref\n",
            "bayesseg/data/books/clinical/169.ref\n",
            "bayesseg/data/books/clinical/170.ref\n",
            "bayesseg/data/books/clinical/171.ref\n",
            "bayesseg/data/books/clinical/172.ref\n",
            "bayesseg/data/books/clinical/173.ref\n",
            "bayesseg/data/books/clinical/174.ref\n",
            "bayesseg/data/books/clinical/175.ref\n",
            "bayesseg/data/books/clinical/176.ref\n",
            "bayesseg/data/books/clinical/177.ref\n",
            "bayesseg/data/books/clinical/178.ref\n",
            "bayesseg/data/books/clinical/179.ref\n",
            "bayesseg/data/books/clinical/180.ref\n",
            "bayesseg/data/books/clinical/181.ref\n",
            "bayesseg/data/books/clinical/182.ref\n",
            "bayesseg/data/books/clinical/183.ref\n",
            "bayesseg/data/books/clinical/184.ref\n",
            "bayesseg/data/books/clinical/185.ref\n",
            "bayesseg/data/books/clinical/186.ref\n",
            "bayesseg/data/books/clinical/187.ref\n",
            "bayesseg/data/books/clinical/188.ref\n",
            "bayesseg/data/books/clinical/189.ref\n",
            "bayesseg/data/books/clinical/190.ref\n",
            "bayesseg/data/books/clinical/191.ref\n",
            "bayesseg/data/books/clinical/192.ref\n",
            "bayesseg/data/books/clinical/193.ref\n",
            "bayesseg/data/books/clinical/194.ref\n",
            "bayesseg/data/books/clinical/195.ref\n",
            "bayesseg/data/books/clinical/196.ref\n",
            "bayesseg/data/books/clinical/197.ref\n",
            "bayesseg/data/books/clinical/198.ref\n",
            "bayesseg/data/books/clinical/199.ref\n",
            "bayesseg/data/books/clinical/200.ref\n",
            "bayesseg/data/books/clinical/201.ref\n",
            "bayesseg/data/books/clinical/202.ref\n",
            "bayesseg/data/books/clinical/203.ref\n",
            "bayesseg/data/books/clinical/204.ref\n",
            "bayesseg/data/books/clinical/205.ref\n",
            "bayesseg/data/books/clinical/206.ref\n",
            "bayesseg/data/books/clinical/207.ref\n",
            "bayesseg/data/books/clinical/208.ref\n",
            "bayesseg/data/books/clinical/209.ref\n",
            "bayesseg/data/books/clinical/210.ref\n",
            "bayesseg/data/books/clinical/211.ref\n",
            "bayesseg/data/books/clinical/212.ref\n",
            "bayesseg/data/books/clinical/213.ref\n",
            "bayesseg/data/books/clinical/214.ref\n",
            "bayesseg/data/books/clinical/215.ref\n",
            "bayesseg/data/books/clinical/216.ref\n",
            "bayesseg/data/books/clinical/217.ref\n",
            "bayesseg/data/books/clinical/218.ref\n",
            "bayesseg/data/books/clinical/219.ref\n",
            "bayesseg/data/books/clinical/220.ref\n",
            "bayesseg/data/books/clinical/221.ref\n",
            "bayesseg/data/books/clinical/222.ref\n",
            "bayesseg/data/books/clinical/223.ref\n",
            "bayesseg/data/books/clinical/224.ref\n",
            "bayesseg/data/books/clinical/225.ref\n",
            "bayesseg/data/books/clinical/226.ref\n",
            "bayesseg/data/books/clinical/init.dp.0\n",
            "bayesseg/data/books/clinical/init.dp.1\n",
            "bayesseg/data/books/clinical/init.dp.2\n",
            "bayesseg/data/books/clinical/init.dp.3\n",
            "bayesseg/data/books/clinical/init.dp.4\n",
            "bayesseg/data/books/clinical/init.dp.5\n",
            "bayesseg/data/books/clinical/init.dp.6\n",
            "bayesseg/data/books/clinical/init.dp.7\n",
            "bayesseg/data/books/clinical/init.dp.8\n",
            "bayesseg/data/books/clinical/init.dp.9\n",
            "bayesseg/data/icsi/scripts/all_icsi2choi.rb\n",
            "bayesseg/data/icsi/scripts/icsi2choi.rb\n",
            "bayesseg/data/icsi/segs/Bed003.ref\n",
            "bayesseg/data/icsi/segs/Bed004.ref\n",
            "bayesseg/data/icsi/segs/Bed011.ref\n",
            "bayesseg/data/icsi/segs/Bmr001.ref\n",
            "bayesseg/data/icsi/segs/Bmr002.ref\n",
            "bayesseg/data/icsi/segs/Bmr005.ref\n",
            "bayesseg/data/icsi/segs/Bmr007.ref\n",
            "bayesseg/data/icsi/segs/Bmr008.ref\n",
            "bayesseg/data/icsi/segs/Bmr009.ref\n",
            "bayesseg/data/icsi/segs/Bmr010.ref\n",
            "bayesseg/data/icsi/segs/Bmr011.ref\n",
            "bayesseg/data/icsi/segs/Bmr012.ref\n",
            "bayesseg/data/icsi/segs/Bmr013.ref\n",
            "bayesseg/data/icsi/segs/Bmr014.ref\n",
            "bayesseg/data/icsi/segs/Bmr018.ref\n",
            "bayesseg/data/icsi/segs/Bmr021.ref\n",
            "bayesseg/data/icsi/segs/Bmr022.ref\n",
            "bayesseg/data/icsi/segs/Bmr024.ref\n",
            "bayesseg/data/icsi/segs/Bmr025.ref\n",
            "bayesseg/data/icsi/segs/Bmr026.ref\n",
            "bayesseg/data/icsi/segs/Bmr027.ref\n",
            "bayesseg/data/icsi/segs/Bmr029.ref\n",
            "bayesseg/data/icsi/segs/Bro004.ref\n",
            "bayesseg/data/icsi/segs/Bro007.ref\n",
            "bayesseg/data/icsi/segs/Bro015.ref\n",
            "bayesseg/data/icsi/segs/README\n",
            "bayesseg/doc/api/allclasses-frame.html\n",
            "bayesseg/doc/api/allclasses-noframe.html\n",
            "bayesseg/doc/api/constant-values.html\n",
            "bayesseg/doc/api/deprecated-list.html\n",
            "bayesseg/doc/api/edu/mit/nlp/MyTextWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/ParaData.html\n",
            "bayesseg/doc/api/edu/mit/nlp/class-use/MyTextWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/class-use/ParaData.html\n",
            "bayesseg/doc/api/edu/mit/nlp/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/nlp/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/nlp/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/nlp/package-use.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/Document.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/InitializableSegmenter.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/PerfectSegmenter.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/SegEval.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/SegResult.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/SegTester.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/SegTesterParams.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/Segment.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/Segmenter.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/Document.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/InitializableSegmenter.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/PerfectSegmenter.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/SegEval.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/SegResult.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/SegTester.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/SegTesterParams.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/Segment.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/class-use/Segmenter.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/BayesWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/DPDocument.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/DPSeg.PriorOptimizer.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/DPSeg.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/I2JInterface.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/class-use/BayesWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/class-use/DPDocument.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/class-use/DPSeg.PriorOptimizer.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/class-use/DPSeg.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/class-use/I2JInterface.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/dp/package-use.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/CuCoSeg.PriorOptimizer.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/CuCoSeg.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/class-use/CuCoSeg.PriorOptimizer.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/class-use/CuCoSeg.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/mcmc/package-use.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/package-use.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/LCSegWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/MCSWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/UIWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/class-use/LCSegWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/class-use/MCSWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/class-use/UIWrapper.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/nlp/segmenter/wrappers/package-use.html\n",
            "bayesseg/doc/api/edu/mit/util/JacobUtil.html\n",
            "bayesseg/doc/api/edu/mit/util/class-use/JacobUtil.html\n",
            "bayesseg/doc/api/edu/mit/util/ling/CountsManager.html\n",
            "bayesseg/doc/api/edu/mit/util/ling/class-use/CountsManager.html\n",
            "bayesseg/doc/api/edu/mit/util/ling/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/util/ling/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/util/ling/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/util/ling/package-use.html\n",
            "bayesseg/doc/api/edu/mit/util/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/util/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/util/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/util/package-use.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/Annealer.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/FastDCM.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/FastDigamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/FastDoubleGamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/FastGamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/FastIntGamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/ResultTracker.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/Results.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/Stats.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/Annealer.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/FastDCM.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/FastDigamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/FastDoubleGamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/FastGamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/FastIntGamma.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/ResultTracker.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/Results.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/class-use/Stats.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/util/stats/package-use.html\n",
            "bayesseg/doc/api/edu/mit/util/weka/LBFGSWrapper.html\n",
            "bayesseg/doc/api/edu/mit/util/weka/class-use/LBFGSWrapper.html\n",
            "bayesseg/doc/api/edu/mit/util/weka/package-frame.html\n",
            "bayesseg/doc/api/edu/mit/util/weka/package-summary.html\n",
            "bayesseg/doc/api/edu/mit/util/weka/package-tree.html\n",
            "bayesseg/doc/api/edu/mit/util/weka/package-use.html\n",
            "bayesseg/doc/api/help-doc.html\n",
            "bayesseg/doc/api/index-all.html\n",
            "bayesseg/doc/api/index.html\n",
            "bayesseg/doc/api/overview-frame.html\n",
            "bayesseg/doc/api/overview-summary.html\n",
            "bayesseg/doc/api/overview-tree.html\n",
            "bayesseg/doc/api/package-list\n",
            "bayesseg/doc/api/resources/inherit.gif\n",
            "bayesseg/doc/api/stylesheet.css\n",
            "bayesseg/eval\n",
            "bayesseg/lib/MinCutSeg.jar\n",
            "bayesseg/lib/colt.jar\n",
            "bayesseg/lib/lingpipe-3.4.0.jar\n",
            "bayesseg/lib/log4j-1.2.14.jar\n",
            "bayesseg/lib/mtj.jar\n",
            "bayesseg/lib/options.jar\n",
            "bayesseg/log.config\n",
            "bayesseg/segment\n",
            "bayesseg/source/edu/mit/nlp/MyTextWrapper.java\n",
            "bayesseg/source/edu/mit/nlp/ParaData.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/Document.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/InitializableSegmenter.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/MultiEval.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/PerfectSegmenter.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/SegEval.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/SegResult.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/SegTester.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/SegTesterParams.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/Segment.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/Segmenter.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/bayesseg\n",
            "bayesseg/source/edu/mit/nlp/segmenter/dp/BayesWrapper.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/dp/DPDocument.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/dp/DPSeg.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/dp/I2JInterface.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/mcmc/CuCoSeg.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/runseg\n",
            "bayesseg/source/edu/mit/nlp/segmenter/wrappers/LCSegWrapper.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/wrappers/MCSWrapper.java\n",
            "bayesseg/source/edu/mit/nlp/segmenter/wrappers/UIWrapper.java\n",
            "bayesseg/source/edu/mit/util/JacobUtil.java\n",
            "bayesseg/source/edu/mit/util/ling/CountsManager.java\n",
            "bayesseg/source/edu/mit/util/ling/Stemmer.java\n",
            "bayesseg/source/edu/mit/util/stats/Annealer.java\n",
            "bayesseg/source/edu/mit/util/stats/FastDCM.java\n",
            "bayesseg/source/edu/mit/util/stats/FastDigamma.java\n",
            "bayesseg/source/edu/mit/util/stats/FastDoubleGamma.java\n",
            "bayesseg/source/edu/mit/util/stats/FastGamma.java\n",
            "bayesseg/source/edu/mit/util/stats/FastIntGamma.java\n",
            "bayesseg/source/edu/mit/util/stats/ResultTracker.java\n",
            "bayesseg/source/edu/mit/util/stats/Results.java\n",
            "bayesseg/source/edu/mit/util/stats/Stats.java\n",
            "bayesseg/source/edu/mit/util/stats/ttest.rb\n",
            "bayesseg/source/edu/mit/util/weka/LBFGSWrapper.java\n",
            "bayesseg/source/riso/numerical/LBFGS.java\n",
            "bayesseg/source/riso/numerical/Mcsrch.java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnU9dhqFoXdB",
        "colab_type": "code",
        "outputId": "b06c3471-6638-4208-cdfa-94d649926428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd bayesseg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bayesseg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRDYhaspoga9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 700 eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxYUNNd0opyW",
        "colab_type": "code",
        "outputId": "b6020623-56b3-4780-9021-aa4fd9b65679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!./eval config/dp.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{use-extra-features=false, careful-debug=false, segmentation-dispersion-range=.1,100,20,M, dirichlet-prior=.2, window-size-range=10,25,16,A, ;;;;;;;;;;=MCMC PARAMS, use-fixed-blocks=false, use-word-stems=true, update-params-period=1000, mcem-cuephrases=false, lambda-b=1, max-move=50, use-choi-style-boundaries=true, segmentation-dispersion=1, remove-stop-words=true, segmenter=edu.mit.nlp.segmenter.dp.BayesWrapper, window-size=10, cooling-duration=.25, ;;=em parameters already plugged in..., num-mcmc-moves=100000, output-period=100, cuephrase-file=config/CUEPHRASES.hl, max-burnin-temp=5, phi-b-0=.01, lambda-o=0, update-lm-period=100, use-duration=false, dirichlet-prior-range=.0001,.1,20,M, em-param-search=false, num-segs-known=true, stop-words=config/STOPWORD.list, phi-o-0=.005, burnin-duration=.25}\n",
            "data/books/clinical/161.ref\n",
            "data/books/clinical/141.ref\n",
            "data/books/clinical/121.ref\n",
            "data/books/clinical/101.ref\n",
            "data/books/clinical/051.ref\n",
            "data/books/clinical/061.ref\n",
            "data/books/clinical/001.ref\n",
            "data/books/clinical/221.ref\n",
            "data/books/clinical/171.ref\n",
            "data/books/clinical/151.ref\n",
            "data/books/clinical/091.ref\n",
            "data/books/clinical/191.ref\n",
            "data/books/clinical/021.ref\n",
            "data/books/clinical/011.ref\n",
            "data/books/clinical/041.ref\n",
            "data/books/clinical/131.ref\n",
            "data/books/clinical/111.ref\n",
            "data/books/clinical/031.ref\n",
            "data/books/clinical/201.ref\n",
            "data/books/clinical/081.ref\n",
            "data/books/clinical/071.ref\n",
            "data/books/clinical/181.ref\n",
            "data/books/clinical/211.ref\n",
            "0.5582 0.5582\n",
            "0.3080 0.3080\n",
            "0.3012 0.3059\n",
            "0.5015 0.5015\n",
            "0.2547 0.2685\n",
            "0.3018 0.3018\n",
            "0.6263 0.6263\n",
            "0.3962 0.4434\n",
            "0.5639 0.5639\n",
            "0.4765 0.4765\n",
            "0.5000 0.5000\n",
            "0.5018 0.5018\n",
            "0.2218 0.2678\n",
            "0.4460 0.4460\n",
            "0.2065 0.2065\n",
            "0.2542 0.2542\n",
            "0.6070 0.6070\n",
            "0.4242 0.4242\n",
            "0.3213 0.3213\n",
            "0.2580 0.2580\n",
            "0.4029 0.4029\n",
            "0.1931 0.1931\n",
            "0.4499 0.4655\n",
            "0.3946 0.4001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfKhb7LOvAKg",
        "colab_type": "text"
      },
      "source": [
        "# New Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBzox9GlIP6r",
        "colab_type": "text"
      },
      "source": [
        "## Clonning for repo based on original data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJUSoJn5vDgc",
        "colab_type": "code",
        "outputId": "b8c0d251-0330-4a30-fa45-ff5191c59e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://snj-adhikari:culblank1minded@github.com/snj-adhikari/bayesian-text-segmentation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bayesian-text-segmentation'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 1092 (delta 27), reused 40 (delta 16), pack-reused 1036\u001b[K\n",
            "Receiving objects: 100% (1092/1092), 8.19 MiB | 25.96 MiB/s, done.\n",
            "Resolving deltas: 100% (372/372), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27sOBT4zvlMU",
        "colab_type": "code",
        "outputId": "a44bc849-2057-4d1f-ce4c-f1bf2958a59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd bayesian-text-segmentation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bayesian-text-segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3ty3fS3vqhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 700 eval\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4CO6mbJ17Up",
        "colab_type": "text"
      },
      "source": [
        "## Gather data using wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKkhKtXU_xrR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The document came fro wikipedia . \n",
        "Got all the links from the following wikipedia article\n",
        "https://en.wikipedia.org/wiki/Music\n",
        "\n",
        "- Took first 20 links from this article and got seperate article for that link to make our two document. \n",
        "\n",
        "- Crated 20 document named *.ref ranging from 0 - 19 , one document for one article from the link on wiki , \n",
        "those document where segmented using 20 to 30 lines segmentation using choi notation.\n",
        "\n",
        "- Random sample *.ref from  0 - 10 , to get 9 articles document. Combined those 9 articles to make single file 1.txt \n",
        "- Again random sample *.ref from 10-19 to get 9 articles document . Combine those 9 articles to make another single file 2.txt\n",
        " \n",
        " - Finally , composite document was made by combining these two documents , splitting them up using \"choi notation\" iteslf,\n",
        " and interleaving the segments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ytU5PbQJh5G6"
      },
      "source": [
        "### Installing the wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a014b58a-c450-4327-e5bd-65b73558f6ad",
        "id": "4sDeIW1kh5G3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!pip install wikipedia"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=84d1d028358e63f96d89ad0b5771a22210755a581a0b1d81728377c6b1d85672\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jifKK2psh5G2"
      },
      "source": [
        "### Downloading NLTK with punkt for tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "994b5934-6349-4b29-bdb3-879d3be05ad5",
        "id": "WLFCKFRZh5Gy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LD1a-viBh5Gv"
      },
      "source": [
        "### Creating Refrence document using individual wiki page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PQzAG9Ych5Gs",
        "colab": {}
      },
      "source": [
        "!rm -r data/music\n",
        "!mkdir data/music\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wIQU0sEIh5Gp"
      },
      "source": [
        "Basically , here we took music wikipedia page to extract all the links based on the music wiki page. From their I took first 20 links and extracted content from those link itself. Then,I used to tokenize package to extract sentences from the wikipedia page. With the help of that I created 20 pages .ref files. Then randomly selected 20 to 30 lines interval and segmented using choi notation.  As a result , the data/music file has now 20 files , named from 0.ref to 20.ref"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAGP9Oiih5Gm"
      },
      "source": [
        "note : some of the segment might have lesser than 20 sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "27721f13-3e1e-4795-ae9e-cdd2b110d624",
        "id": "GLquLwk4h5Gd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import wikipedia as wiki\n",
        "import random\n",
        "import nltk.data\n",
        "\n",
        "tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n",
        "\n",
        "music = wiki.page(\"music\").links\n",
        "\n",
        "\n",
        "step = 0 \n",
        "for i in music[:20]:\n",
        "    base_data = \"\"\n",
        "    try:\n",
        "      p = wiki.page(i)\n",
        "    except wiki.exceptions.DisambiguationError as e:\n",
        "      s = random.choice(e.options)\n",
        "#       search = wiki.search(s)\n",
        "#       s = random.choice(search)\n",
        "#       print(\"the ambigious is \" , s)\n",
        "      p = wiki.page(s)\n",
        "    except wiki.exceptions.PageError as e:\n",
        "#       print(\"error on getting page\")\n",
        "      search= wiki.search(music[i])\n",
        "      s = random.choice(search)\n",
        "      p = wiki.page(s)\n",
        "      \n",
        "    new_data = p.content\n",
        "    \n",
        "    analyzed_data = new_data.replace(\"=\" , \" --\")\n",
        "#     print(\"the aanlayzed data is\" , len(analyzed_data.split()))\n",
        "    tokenized_data  = tokenizer.tokenize(analyzed_data)\n",
        "    suffle_sen = random.randint(20,30)\n",
        "#     print(\"the suffle sen is\" , suffle_sen)\n",
        "    step_token= len(tokenized_data)//suffle_sen\n",
        "    \n",
        "#     print(\"the step is\" , step_token)\n",
        "    for count in range(step_token) : \n",
        "      segmented_data = ''.join(tokenized_data[count *suffle_sen : (count+1) * suffle_sen]) \n",
        "      base_data = base_data + segmented_data +  \"\\n==========\\n\"\n",
        "    \n",
        "    if step_token <= 0 :\n",
        "      segmented_data = ''.join(tokenized_data)\n",
        "      base_data = base_data + segmented_data + \"\\n==========\\n\"\n",
        "     \n",
        "    words = len(base_data.split())\n",
        "  \n",
        "    text_file = open('data/music/'+str(step)+'.ref', 'w' )\n",
        "    step  = step+ 1\n",
        "    text_file.write(base_data)\n",
        "    text_file.close()\n",
        "\n",
        "    print(\"paragraph words written in file is \" , words)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paragraph words written in file is  1944\n",
            "paragraph words written in file is  2620\n",
            "paragraph words written in file is  2372\n",
            "paragraph words written in file is  895\n",
            "paragraph words written in file is  1388\n",
            "paragraph words written in file is  1816\n",
            "paragraph words written in file is  3310\n",
            "paragraph words written in file is  627\n",
            "paragraph words written in file is  4081\n",
            "paragraph words written in file is  14182\n",
            "paragraph words written in file is  435\n",
            "paragraph words written in file is  853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "paragraph words written in file is  572\n",
            "paragraph words written in file is  2979\n",
            "paragraph words written in file is  388\n",
            "paragraph words written in file is  998\n",
            "paragraph words written in file is  3588\n",
            "paragraph words written in file is  2498\n",
            "paragraph words written in file is  4856\n",
            "paragraph words written in file is  10377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbSB3-kXi547",
        "colab_type": "text"
      },
      "source": [
        "### Checking the segmentation of reference file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ad17a96-e4a1-4ff3-ce1b-cfd7356cc7e4",
        "id": "oAa6_IFuh5GO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!chmod 700 segment\n",
        "!cat \"data/music/1.ref\" | ./segment config/dp.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 20, 27, 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KzC6YqMUrcc",
        "colab_type": "text"
      },
      "source": [
        "## Creating new dataset document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTtnwusVhItb",
        "colab_type": "text"
      },
      "source": [
        "### First creating two different text document "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ_45NriUyyd",
        "colab_type": "text"
      },
      "source": [
        "Created a composite directory , made 2 composite document with random sample of  9 files between range(10) and range(10,20)Basically first range give files from 0.ref to 9.ref and second range gives file from 10.ref  to 19.ref "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3UprTOaIqO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r data/composite\n",
        "!mkdir data/composite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX8k_WDGGwu1",
        "colab_type": "code",
        "outputId": "93c1d969-8121-4008-b7b3-0f568cb7216e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import random \n",
        "total_no_first = range(10)\n",
        "total_no_second = range(10,20)\n",
        "\n",
        "\n",
        "sample_1 = random.sample(total_no_first, k=9)\n",
        "sample_2 = random.sample(total_no_second, k=9)\n",
        "\n",
        "data = \"\"\n",
        "for i in sample_1:\n",
        "  f = open(\"data/music/\"+str(i)+\".ref\", \"r\")\n",
        "  data = data + f.read()\n",
        "  f.close()\n",
        "  \n",
        "  \n",
        "print(\"the data length is\" , len(data.split()))\n",
        "new_file = open(\"data/composite/1.txt\" , 'w')\n",
        "\n",
        "new_file.write(data)\n",
        "  \n",
        "new_file.close()\n",
        "  \n",
        "  \n",
        "data = \"\"\n",
        "for i in sample_2 :\n",
        "  f = open(\"data/music/\"+str(i)+\".ref\", \"r\")\n",
        "  data = data + f.read()\n",
        "  f.close()\n",
        "  \n",
        "  \n",
        "print(\"the data length is\" , len(data.split()))\n",
        "  \n",
        "  \n",
        "new_file = open(\"data/composite/2.txt\" , 'w')\n",
        "\n",
        "new_file.write(data)\n",
        "\n",
        "new_file.close()\n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the data length is 32340\n",
            "the data length is 22688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syJ3RKuqV4HO",
        "colab_type": "text"
      },
      "source": [
        "note : Got two document 1.txt and 2.txt basically around 24000 words to 35000 words each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiUTTxlL484C",
        "colab_type": "text"
      },
      "source": [
        "### Making the composite document , merging two document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hltM03QWYO-",
        "colab_type": "text"
      },
      "source": [
        "Now taking two composite file creating making combined  document  using alternative segment from each file to combined document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVJDH1LP35_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r data/combined\n",
        "!mkdir data/combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULSJnxcLZryM",
        "colab_type": "text"
      },
      "source": [
        "Create your artificial dataset by taking two documents i.e. 1.txt and 2.txt combined with different topics, splitting them up, and interleaving the segments.  \n",
        "\n",
        "doc1_seg1 doc2_seg1 doc1_seg2 doc2_seg2 ... doc1_segN doc2_s\n",
        "\n",
        "where \n",
        "doc1 = 1.txt  \n",
        "seg = segment seperated by choi notation in previous data formation \n",
        "\n",
        "doc 2 = 2.txt ,  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vhGxM0c3ec8",
        "colab_type": "code",
        "outputId": "1ca957fe-875c-4805-85c4-9a0730d374d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "array_split = []\n",
        "f = open(\"data/composite/1.txt\", \"r\")\n",
        "data_1 =  f.read()\n",
        "array_split_1 = data_1.split('==========')\n",
        "f.close()\n",
        "\n",
        "\n",
        "f2 = open(\"data/composite/2.txt\", \"r\")\n",
        "data_2 =  f2.read()\n",
        "array_split_2 = data_2.split('==========')\n",
        "f2.close()\n",
        "  \n",
        "  \n",
        "print(\"the array split data is\" , len(array_split_1))\n",
        "print(\"the array split second data is\" , len(array_split_2))\n",
        "new_data = \"==========\\n\"\n",
        "if(len(array_split_1)>len(array_split_2)):\n",
        "  for first in range(0, len(array_split_2)-1):\n",
        "    new_data = new_data + array_split_1[first] + \"==========\\n\" + array_split_2[first] + \"==========\\n\"\n",
        "else : \n",
        "  for second in range(0, len(array_split_1)-1):\n",
        "    new_data = new_data + array_split_1[second] + \"==========\\n\" + array_split_2[second] + \"==========\\n\"\n",
        "\n",
        "\n",
        "new_comp_file = open(\"data/combined/composite.txt\" , 'w')\n",
        "\n",
        "new_comp_file.write(new_data)\n",
        "  \n",
        "new_file.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the array split data is 54\n",
            "the array split second data is 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl-EXySz-PwQ",
        "colab_type": "code",
        "outputId": "1ca8dd06-424a-4466-da0d-2308ed84b19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/snj-adhikari/bayesian-text-segmentation\n",
            "   cd4aa5f..764cfb6  master     -> origin/master\n",
            "Updating cd4aa5f..764cfb6\n",
            "Fast-forward\n",
            " eval | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8a3bXtihAF1",
        "colab_type": "text"
      },
      "source": [
        "## Testing new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqDnAEDNFCu3",
        "colab_type": "code",
        "outputId": "906fa9f5-e6c5-40fc-f4c7-c2d9ea896e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!chmod 700 eval\n",
        "!./eval config/dp.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{use-extra-features=false, careful-debug=false, segmentation-dispersion-range=.1,100,20,M, dirichlet-prior=.2, window-size-range=10,25,16,A, ;;;;;;;;;;=MCMC PARAMS, use-fixed-blocks=false, use-word-stems=true, update-params-period=1000, mcem-cuephrases=false, lambda-b=1, max-move=50, use-choi-style-boundaries=true, segmentation-dispersion=1, remove-stop-words=true, segmenter=edu.mit.nlp.segmenter.dp.BayesWrapper, window-size=15, cooling-duration=.25, ;;=em parameters already plugged in..., num-mcmc-moves=100000, output-period=100, cuephrase-file=config/CUEPHRASES.hl, max-burnin-temp=5, phi-b-0=.01, lambda-o=0, update-lm-period=100, use-duration=false, dirichlet-prior-range=.0001,.1,20,M, em-param-search=false, num-segs-known=true, stop-words=config/STOPWORD.list, phi-o-0=.005, burnin-duration=.25}\n",
            "data/combined/composite.txt\n",
            "0.4184 0.4920\n",
            "0.4184 0.4920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCts8WUC-MhO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The result  is similar to the  baysian paper. \n",
        "\n",
        "The result is average , the idea result was 0 for perfect segmentation. \n",
        "But our result is arround 0.5 for windDiff and 0.44 for pk which we can consider ideal for random segmentation.\n",
        "Since our segmentation is random it is giving WinDiff around 0.5  i.e 0.49 \n",
        "\n",
        "while pk is close to 0.4184 . So we are some what successfull to make random segmentation rather than the ideal segmentation \n",
        "with our new dataset. \n",
        "\n",
        "Also , PK will be less than winDiff same as the paper. \n",
        "\n",
        "Hence , we were able to replicate the bayesian topic segmentation code with the new data successfully.\n",
        "\n",
        "**To conclude , we could consider the result is sufficiently good enough for random segmentation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGJwA9-VIfAZ",
        "colab_type": "text"
      },
      "source": [
        "## Pushing the changes into git so that it can be use be used in amazon VM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bwj0x0O72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git config --global user.email \"adhikari.snj@gmail.com\"\n",
        "!git config --global user.name \"Sanjay Adhikari\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEtbWT3S0sQQ",
        "colab_type": "code",
        "outputId": "b5747d88-09d6-45f0-e37e-25f4428b9a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!git add *\n",
        "!git commit -m \"ongoing changes\"\n",
        "!git push"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master dce41a3] ongoing changes\n",
            " 1 file changed, 40 insertions(+), 40 deletions(-)\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (5/5), 659 bytes | 659.00 KiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/snj-adhikari/bayesian-text-segmentation\n",
            "   ad863f3..dce41a3  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}